{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e37972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig , AutoTokenizer , AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4420aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\32721\\anaconda3\\envs\\transformers\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\32721\\.cache\\huggingface\\hub\\models--hfl--rbt3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ff9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce7edbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f244e8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 1922, 2358, 1492,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"我太帅咯\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "inputs = tokenizer(sen, return_tensors = \"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf447b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0957,  1.2593,  0.6565,  ..., -0.2068,  0.5412,  0.2499],\n",
       "         [ 0.7607,  0.2709,  0.3775,  ...,  0.1706,  0.3549, -0.3088],\n",
       "         [ 0.0388,  0.3341,  0.0455,  ...,  0.2649,  0.2959, -0.0484],\n",
       "         [ 0.2501,  0.3075,  0.2341,  ..., -0.0087,  0.3531, -0.3608],\n",
       "         [ 0.0790,  0.4614,  0.0420,  ..., -0.2230,  0.1972, -0.4308],\n",
       "         [ 0.0913,  1.2690,  0.6553,  ..., -0.2018,  0.5416,  0.2495]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-3.6923e-01, -9.9986e-01, -1.0000e+00,  4.9523e-01,  9.9821e-01,\n",
       "         -1.2925e-01, -7.7136e-02, -7.0166e-02,  9.9936e-01,  9.9989e-01,\n",
       "          7.6059e-02, -1.0000e+00,  2.8109e-01,  9.9960e-01, -1.0000e+00,\n",
       "          9.9998e-01,  9.9924e-01,  8.0197e-01, -9.5526e-01,  5.0360e-02,\n",
       "         -9.4607e-01, -9.9148e-01,  3.5530e-01,  9.8804e-01,  9.7798e-01,\n",
       "         -9.9902e-01, -9.9996e-01, -3.0697e-01, -9.8748e-01, -9.9999e-01,\n",
       "         -9.8239e-01, -9.9923e-01,  2.1677e-01,  3.0032e-02,  9.9774e-01,\n",
       "         -5.0522e-01,  1.9561e-01, -3.7898e-01, -9.9756e-01, -9.9688e-01,\n",
       "          1.2603e-01,  9.7380e-01,  5.4684e-03,  9.9500e-01,  3.1168e-01,\n",
       "         -1.3203e-01,  9.9999e-01,  8.2795e-01, -4.7604e-01, -9.8628e-02,\n",
       "         -1.3309e-01, -7.0526e-02, -9.9759e-01,  9.9627e-01, -2.0833e-01,\n",
       "          3.0966e-02,  9.9460e-01, -1.0000e+00, -9.9995e-01,  9.9786e-01,\n",
       "         -9.9995e-01,  9.9837e-01,  9.9982e-01,  9.8690e-01, -5.5326e-01,\n",
       "          9.9847e-01,  9.9465e-01,  9.9946e-01, -5.2960e-01, -1.0000e+00,\n",
       "          7.7554e-01, -7.5681e-01, -9.6999e-01, -5.0264e-02,  7.1932e-02,\n",
       "         -9.9993e-01,  9.9589e-01,  8.0961e-02,  9.9999e-01,  4.5944e-01,\n",
       "         -9.7379e-01, -1.9754e-01,  9.6450e-02,  1.9107e-01,  9.8914e-01,\n",
       "          1.0000e+00,  3.9823e-01, -9.6069e-01, -2.9384e-01, -9.9801e-01,\n",
       "         -6.0150e-01,  9.9970e-01,  9.9999e-01, -9.9989e-01,  9.9999e-01,\n",
       "         -9.8599e-01,  1.8697e-01, -1.2933e-01, -9.9650e-01,  9.9813e-01,\n",
       "         -4.6431e-01, -1.9903e-01,  1.0000e+00,  9.9968e-01,  8.4130e-01,\n",
       "         -9.8212e-01, -9.9876e-01,  9.9946e-01, -9.3860e-01,  1.2911e-01,\n",
       "          9.9991e-01,  9.8551e-01,  1.0000e+00,  9.9911e-01,  9.9999e-01,\n",
       "         -9.9994e-01, -4.2400e-02, -1.8804e-02, -9.9994e-01,  9.9988e-01,\n",
       "         -9.8749e-01, -2.3196e-01, -9.3497e-01,  1.5221e-01, -9.1374e-02,\n",
       "         -9.9950e-01,  1.3198e-01,  4.5324e-01, -9.9974e-01, -9.9947e-01,\n",
       "         -9.9473e-01, -9.9959e-01,  9.7239e-01,  9.5752e-01,  9.9229e-01,\n",
       "         -8.7638e-02,  7.3081e-02, -9.4796e-02, -9.9834e-01, -9.9995e-01,\n",
       "         -9.9948e-01, -3.4302e-01, -8.2786e-01,  9.6462e-01, -9.9967e-01,\n",
       "          8.5918e-01, -9.9976e-01,  9.9999e-01,  9.6062e-01, -2.3599e-01,\n",
       "          6.3312e-01,  1.4366e-01, -9.9988e-01,  3.5471e-01, -5.7295e-02,\n",
       "          9.3190e-01,  9.8601e-01,  9.9456e-01,  8.8918e-01,  9.9988e-01,\n",
       "         -9.9631e-01,  8.2372e-01,  5.6048e-01,  9.8871e-01,  1.0000e+00,\n",
       "         -9.9997e-01,  1.1891e-01, -9.9998e-01, -7.7764e-02, -1.1174e-01,\n",
       "          9.9997e-01,  9.9307e-01,  9.8209e-01,  9.5702e-01, -8.0661e-01,\n",
       "         -9.9942e-01,  7.5765e-01, -9.9273e-01,  3.9592e-01,  1.0000e+00,\n",
       "          9.9093e-02, -9.1851e-01,  1.0000e+00, -9.5487e-01,  9.9978e-01,\n",
       "          5.6228e-02, -3.9635e-01, -9.9821e-01,  3.9126e-01,  9.3477e-01,\n",
       "          9.8142e-01, -9.1696e-01, -2.8619e-01,  9.9298e-01, -1.0159e-01,\n",
       "         -2.1809e-01, -9.9886e-01, -9.9289e-01,  9.9997e-01,  9.9894e-01,\n",
       "          1.3986e-01, -2.8851e-01,  1.0000e+00,  6.0026e-01,  9.9991e-01,\n",
       "          1.6108e-01,  8.8105e-01, -5.5964e-01,  9.6650e-01,  5.0440e-01,\n",
       "          9.8528e-01,  1.5064e-02,  9.9999e-01, -9.8280e-01, -9.9995e-01,\n",
       "          2.8724e-02, -7.9375e-01,  9.4192e-03, -9.6706e-01,  7.6727e-01,\n",
       "         -3.1078e-01,  9.9998e-01, -4.6143e-02, -8.9665e-01,  9.7245e-01,\n",
       "         -9.9982e-01,  9.7872e-01, -9.9993e-01, -9.9985e-01,  9.9990e-01,\n",
       "         -4.3786e-01, -1.0000e+00,  9.6506e-01,  9.9998e-01, -7.7037e-01,\n",
       "          9.9218e-01, -2.2124e-02, -9.9980e-01, -2.7204e-01, -4.1766e-02,\n",
       "         -1.0000e+00, -9.9510e-01, -1.0000e+00, -9.9563e-01,  3.1413e-02,\n",
       "          9.9753e-01, -9.9999e-01, -9.1333e-02, -9.9651e-01,  9.8935e-01,\n",
       "          9.9992e-01,  1.4313e-01,  1.5903e-02,  9.9999e-01, -9.7615e-01,\n",
       "          1.1427e-01, -3.1528e-01, -2.4032e-01, -1.0551e-01,  8.0497e-01,\n",
       "         -1.6472e-01,  9.9993e-01, -9.9995e-01, -8.1988e-02,  6.8066e-01,\n",
       "         -9.9904e-01, -2.5608e-02,  7.9017e-01,  1.0212e-01,  2.7040e-01,\n",
       "         -4.9071e-02,  3.0810e-01,  9.8814e-01,  9.0583e-01,  1.0000e+00,\n",
       "          9.9848e-01,  1.0000e+00,  1.0000e+00, -3.5122e-01, -9.9620e-01,\n",
       "         -9.1396e-01,  1.7543e-01, -9.9997e-01, -7.6428e-01, -9.9912e-01,\n",
       "          9.9600e-01, -4.2113e-01,  1.0000e+00, -9.9999e-01,  1.0000e+00,\n",
       "         -9.9296e-01,  2.7624e-01, -3.9155e-02, -1.8132e-01,  4.4512e-01,\n",
       "         -1.9511e-01,  9.8446e-01,  2.4803e-01,  9.8096e-01,  9.6745e-01,\n",
       "         -1.5140e-01, -2.5492e-01,  1.1520e-01,  2.7838e-01,  9.9959e-01,\n",
       "         -9.9645e-01,  9.7483e-01,  1.3463e-01,  9.9339e-01, -9.7930e-02,\n",
       "         -9.9953e-01,  9.9991e-01, -9.9591e-01,  4.4318e-01, -9.9998e-01,\n",
       "         -9.6197e-01,  2.3516e-01, -9.9944e-01,  7.0402e-01,  9.6381e-01,\n",
       "          1.6768e-01,  1.8999e-01, -9.9999e-01, -9.5251e-01,  9.7613e-01,\n",
       "          9.9988e-01, -9.9999e-01,  9.9834e-01,  9.7369e-01, -2.4354e-01,\n",
       "          2.9588e-01,  5.6677e-01, -9.9583e-01,  9.9999e-01, -1.0000e+00,\n",
       "         -3.2415e-01,  9.8605e-01,  2.8688e-01, -9.9993e-01, -2.6427e-01,\n",
       "         -3.3388e-01,  9.6765e-01, -1.2768e-01,  1.0000e+00, -4.4220e-01,\n",
       "          2.1781e-01, -9.9999e-01, -9.8963e-01, -6.4732e-01, -3.9909e-03,\n",
       "          9.9977e-01, -9.9992e-01,  9.6099e-01,  9.9964e-01, -9.8856e-01,\n",
       "         -2.9274e-01, -5.2731e-02, -1.6841e-01,  2.8938e-01, -9.8067e-01,\n",
       "         -9.9998e-01, -9.8982e-01,  9.9999e-01, -2.1639e-02, -1.1402e-01,\n",
       "          9.9964e-01,  9.9211e-01,  9.9993e-01, -9.9713e-01,  9.9331e-01,\n",
       "          9.9996e-01,  3.2300e-01, -1.3012e-01,  6.0502e-01, -1.7171e-02,\n",
       "          3.0100e-01, -9.8565e-01,  8.0962e-02,  5.8521e-01, -6.2221e-01,\n",
       "         -8.4880e-01,  9.9845e-01,  9.9999e-01,  1.0000e+00, -2.3759e-01,\n",
       "         -9.8044e-01,  9.3198e-01, -9.4808e-01, -9.9886e-01, -3.6838e-02,\n",
       "          9.9960e-01, -9.9970e-01,  4.2467e-01, -5.6797e-01, -9.8251e-01,\n",
       "          9.9857e-01, -9.9998e-01, -1.5238e-01, -1.0000e+00, -9.9993e-01,\n",
       "         -1.0000e+00,  1.0000e+00,  1.4566e-02,  1.9898e-01, -9.9944e-01,\n",
       "          1.0000e+00,  9.9421e-01, -3.2234e-01,  1.9424e-01,  9.9998e-01,\n",
       "         -1.6311e-02, -8.6982e-01, -1.0000e+00, -9.2035e-01,  9.9859e-01,\n",
       "         -3.0151e-01,  9.9979e-01, -2.5706e-02, -9.9996e-01,  2.1515e-01,\n",
       "          9.9579e-01,  1.5811e-01, -9.9871e-01, -9.9939e-01,  2.4662e-01,\n",
       "         -1.6463e-01, -2.3415e-02, -3.7640e-01,  4.7771e-02,  9.9986e-01,\n",
       "         -3.3834e-01, -3.5352e-01,  2.3713e-01,  9.9995e-01,  3.4090e-01,\n",
       "         -9.9890e-01, -9.9761e-01,  7.3168e-02, -9.9203e-01, -9.8709e-01,\n",
       "         -9.9998e-01, -4.5225e-03,  2.0292e-02,  2.9853e-03, -9.9923e-01,\n",
       "         -9.9988e-01, -9.9986e-01,  4.0365e-01, -8.6446e-01, -9.5389e-01,\n",
       "          2.5441e-01, -9.9902e-01, -9.1437e-01,  7.3276e-01, -9.9598e-01,\n",
       "          2.5525e-01,  9.9615e-01,  9.9534e-01, -9.9997e-01, -3.4698e-01,\n",
       "          9.9911e-01, -9.8672e-01,  2.7054e-02, -9.6910e-01,  3.3023e-01,\n",
       "         -9.9634e-01, -9.9925e-01,  2.7659e-01,  9.9979e-01,  9.8773e-01,\n",
       "          8.6921e-01,  9.9794e-01, -7.0722e-01,  9.9939e-01,  9.9526e-01,\n",
       "          1.0000e+00, -3.9240e-01, -2.0469e-01, -9.9998e-01,  9.8838e-01,\n",
       "          9.3561e-01,  3.8230e-01,  9.5086e-01, -9.9943e-01, -1.7905e-01,\n",
       "         -5.4059e-01,  2.0596e-01,  1.0000e+00,  9.5343e-01,  1.3255e-01,\n",
       "         -9.9999e-01,  3.3744e-01, -4.1675e-01, -9.9824e-02, -8.9443e-01,\n",
       "          1.6658e-01,  1.0000e+00, -8.9959e-01,  4.1605e-01, -9.9988e-01,\n",
       "         -9.9959e-01,  9.9943e-01, -1.0000e+00,  9.9999e-01,  9.9515e-01,\n",
       "         -9.8084e-01, -1.4910e-01,  3.3725e-01, -6.2180e-02,  1.8623e-01,\n",
       "          1.1552e-01, -6.7985e-02, -1.7041e-01, -1.0000e+00, -1.4986e-02,\n",
       "          9.9847e-01, -3.4043e-01, -9.9870e-01, -9.9915e-01,  4.0316e-02,\n",
       "          9.9926e-01, -9.5727e-01, -9.9999e-01, -4.4517e-01, -2.6469e-01,\n",
       "          5.9777e-01, -9.4175e-02, -1.9972e-02,  4.8536e-02, -8.5076e-01,\n",
       "         -7.3259e-02,  9.5466e-01, -9.6552e-01,  9.2777e-01, -9.9685e-01,\n",
       "         -9.3788e-01, -3.1354e-01,  9.9049e-01,  9.9935e-01, -9.9959e-01,\n",
       "         -9.9947e-01, -6.2907e-01, -4.9703e-03, -8.8685e-01,  9.9773e-01,\n",
       "         -4.0607e-01, -9.9911e-01, -7.1073e-02,  2.7055e-01, -4.2282e-01,\n",
       "         -8.6960e-01,  1.0000e+00, -9.9936e-01,  1.0000e+00, -9.9989e-01,\n",
       "          1.0886e-01,  8.4485e-02,  9.9999e-01, -9.9999e-01, -3.0300e-01,\n",
       "          9.9900e-01, -1.0000e+00, -3.8809e-01, -9.7176e-01,  9.1859e-01,\n",
       "         -2.3218e-01,  1.1645e-01,  8.4143e-01, -9.9967e-01,  5.5002e-03,\n",
       "         -9.9931e-01, -4.2189e-01,  9.9853e-01, -9.9997e-01, -9.1060e-01,\n",
       "         -9.9998e-01, -6.6383e-04, -8.0446e-02, -9.9998e-01,  9.3958e-01,\n",
       "          9.9999e-01, -3.0868e-01,  9.7276e-01, -9.9996e-01, -1.4080e-01,\n",
       "         -5.7757e-03, -9.9833e-01,  2.7720e-01, -9.9998e-01, -6.2706e-01,\n",
       "         -9.9974e-01,  7.2180e-01, -9.9999e-01,  5.6316e-01,  9.9619e-01,\n",
       "         -4.5239e-01, -6.8660e-01, -8.2339e-02,  2.0779e-01, -9.9996e-01,\n",
       "         -3.5961e-01, -9.9968e-01, -9.9987e-01, -3.1607e-01,  9.9931e-01,\n",
       "          7.0158e-01,  2.5881e-01,  9.6924e-01, -8.8281e-01,  2.4972e-01,\n",
       "         -1.0373e-01,  9.9272e-01,  1.0000e+00, -9.8438e-01, -9.7447e-01,\n",
       "          9.9316e-01, -9.9998e-01, -6.0286e-01,  9.9999e-01,  7.0710e-01,\n",
       "          9.9989e-01,  2.0807e-01, -9.8389e-01,  1.5671e-01,  2.9298e-02,\n",
       "          9.1440e-01, -5.5763e-02,  2.1068e-01,  9.9995e-01, -1.3953e-01,\n",
       "          4.0692e-01, -8.3632e-01,  9.4558e-01, -2.0637e-03, -4.5765e-01,\n",
       "          9.1774e-01, -9.1873e-01, -9.8204e-01, -9.9982e-01,  4.8123e-01,\n",
       "         -5.4138e-01,  3.3867e-01, -1.9860e-01, -6.0950e-01,  9.9999e-01,\n",
       "         -9.9980e-01,  6.8393e-01, -1.0000e+00, -9.9998e-01,  3.2497e-03,\n",
       "          1.9819e-01,  9.9987e-01,  3.3852e-01, -3.0637e-01, -4.3845e-02,\n",
       "         -9.9695e-01,  9.9961e-01, -9.7141e-01,  9.8206e-01, -1.0052e-01,\n",
       "         -3.4787e-02,  9.9801e-01,  9.9892e-01,  1.4111e-01, -9.9635e-01,\n",
       "         -9.3091e-01,  5.5816e-02, -9.9984e-01,  9.9990e-01,  1.5501e-01,\n",
       "         -3.6026e-02,  3.2419e-01,  3.6309e-02, -9.9845e-01, -9.9965e-01,\n",
       "          3.5348e-01,  9.5113e-01, -9.9999e-01,  5.4067e-01, -9.9515e-01,\n",
       "          9.8462e-01,  9.9997e-01,  1.0000e+00, -1.4301e-02,  4.9814e-01,\n",
       "         -9.9941e-01, -9.9635e-01,  9.3699e-01,  9.1492e-01,  9.9996e-01,\n",
       "          8.3294e-01,  8.1001e-01,  2.0943e-01, -9.9996e-01,  9.9280e-01,\n",
       "         -1.1901e-01, -3.8616e-01,  6.1116e-02, -7.5488e-01, -9.9999e-01,\n",
       "          9.9978e-01, -9.9966e-01, -9.9955e-01, -8.8836e-01, -9.9990e-01,\n",
       "          9.9901e-01,  9.9178e-01,  9.9907e-01,  7.7239e-01, -9.9965e-01,\n",
       "         -9.8997e-01, -3.9295e-02, -9.4615e-01, -9.9886e-01,  3.9620e-01,\n",
       "         -1.0000e+00,  3.8888e-01,  3.4192e-01, -5.3776e-01, -4.1133e-01,\n",
       "         -7.0495e-01,  8.8709e-01,  9.9975e-01, -6.5751e-01,  9.6152e-01,\n",
       "         -5.7111e-01, -9.9986e-01, -1.3888e-01, -1.0000e+00,  9.9513e-01,\n",
       "          9.9999e-01, -4.7410e-01,  9.9891e-01, -8.3010e-01,  2.3952e-01,\n",
       "         -9.9993e-01, -1.0000e+00,  9.5064e-01,  9.9998e-01,  2.0785e-01,\n",
       "         -9.9966e-01, -1.9950e-01, -9.9994e-01, -4.7067e-02,  8.3258e-01,\n",
       "          9.9926e-01, -9.9999e-01,  9.9903e-01, -4.1339e-01,  1.6920e-01,\n",
       "          8.2929e-01, -1.0000e+00, -8.7253e-01, -9.9944e-01,  9.9937e-01,\n",
       "         -1.0000e+00,  9.9143e-01, -6.1932e-01, -1.0367e-01, -6.9882e-02,\n",
       "          9.6061e-01, -9.9971e-01, -7.2725e-01,  9.8347e-01,  9.6962e-01,\n",
       "         -4.3606e-01,  9.9843e-01,  1.8620e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e4ff4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74179b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6893b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00251049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.2755,  0.1481]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC_model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\")\n",
    "SC_model(**inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
